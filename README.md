## Insurance Claim Severity Prediction using Ensemble Machine Learning

This project aims to leverage data science techniques to predict the severity and cost of insurance claims for AllState, a personal insurance company in the United States. By applying ensemble machine learning algorithms and best practices in data analytics, we seek to provide valuable insights and predictive models for post-unforeseen event scenarios.

### Project Highlights:

- **Business Problem**: AllState aims to enhance its understanding of insurance claim severity and cost following unforeseen events. The project focuses on developing accurate predictive models to assist in decision-making processes and risk assessment.

- **Tech Stack**: The project utilizes the Python programming language along with popular data science libraries, including pandas, NumPy, seaborn, matplotlib, sklearn, and SHAP. These libraries provide powerful tools for data manipulation, visualization, and implementing machine learning algorithms.

- **Exploratory Data Analysis**: I extensively analyze the Allstate insurance claim dataset to gain insights into the underlying patterns and characteristics. Through techniques such as 5-point summary analysis, data distribution exploration, and handling missing values, I developed a comprehensive understanding of the data.

- **Feature Selection and Model Building**: By employing statistical tests such as correlation analysis, constant variance tests, and Chi-Square tests, I identified the most relevant features for predicting claim severity and cost. Ensemble machine learning algorithms are then implemented, ensuring accurate predictions and robust model performance.

- **Model Evaluation and Hyper-parameter Tuning**: I evaluate and compare different models using the Root Mean Square Error (RMSE) metric, enabling us to select the most effective model. Hyper-parameter tuning techniques using Sklearn functions are applied to optimize model performance.

- **Model Deployment and Experiment Tracking**: The final predictive model is deployed as a FlaskAPI, allowing seamless integration into a production environment. MLFoundry, a comprehensive ML monitoring, and experiment tracking solution, is utilized to log experiments, models, metrics, data, and features, enabling the generation of informative dashboards and insights.

### Instructions for Running the Project:

1. Clone the repository to your local machine.
2. Install the required Python libraries mentioned in the Tech Stack section using `pip` or `conda`.
3. Execute the Jupyter Notebook files in sequential order to replicate the data analysis, model building, and evaluation processes.
4. Refer to the documentation and code comments for detailed explanations of the project components and methodologies.
5. Follow the FlaskAPI deployment instructions provided in the designated section to utilize the predictive model in a production environment.
6. For further insights and experiment tracking, refer to the MLFoundry documentation integrated within the project.

I hope this project provides valuable insights into insurance claim severity prediction and serves as a comprehensive example of data science best practices and ensemble machine learning techniques. Contributions and feedback are welcome!

Enjoy exploring the project and predicting insurance claim severity with machine learning!

